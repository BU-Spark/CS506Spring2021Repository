# Team Meeting on 2/23/21

## Notes 

- Began by looking for the data sets (The meeting started before we recived the email from Ryan)
- Explored a little into gis files and how we could open and convert that to useable data, put this on hold when we saw Ryan's email
- The rest will be split based on the data set.

### Ookla Dataset  
- Downloaded the Apache Parquet file for the first quarter of 2020 just to get a sense of what was going on
- Figured out how to view the data from the command line via `parquet-tools` and the command `parquet-tools cat --json <filepath/filename>`
- Did exploration on how to transform this into a more usabel file format like csv. The Python package Pandas has support for this and after installing the dependecies we were able to mock up a simple program to convert the file. Found in the GitHub as `parquet_to_csv.py`

### Mlab Dataset
- Created a group google acount to run queries against the google service
- Determined that the data for all of MA was too large to download (600 gigs)
- Began the process of workshoping a program that would act as a level of abstraction between the big dataset and the user requests. Would run custom SQL quereies to get relevant data averages for X number of points and then build an API to access that relevant data.
- The advantage of doing is that this would allow us to store the relevant data point on a machine without taking up insane amounts of space.  
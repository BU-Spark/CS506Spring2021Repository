{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
<<<<<<< HEAD
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('bu_cs': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f34782dca7896296409761b863e490f652f0d0cf99d3e83ed26734792b4da235"
    }
=======
   "name": "python37964bitbucsconda814fbdd8514740bdad0844612087b1b4",
   "display_name": "Python 3.7.9 64-bit ('bu_cs': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f34782dca7896296409761b863e490f652f0d0cf99d3e83ed26734792b4da235"
>>>>>>> AR_D1
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 1,
=======
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
>>>>>>> AR_D1
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "\n",
<<<<<<< HEAD
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation,TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
=======
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "source": [
    "## Global Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
>>>>>>> AR_D1
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_TORNADOS = 108 #Number of Tornado Events\n",
    "NUMBER_RANDOM = 110 #Number of Random Events\n",
<<<<<<< HEAD
    "NUMBER_DAYS = 57 #Number of days of data per Tornado/Event\n",
=======
    "NUMBER_DAYS = 14 #Number of days of data per Tornado/Event (Max: 57)\n",
>>>>>>> AR_D1
    "FILE_NAME = \"all_weather.csv\" #CSV file that contains the data"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 3,
=======
   "source": [
    "## Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
>>>>>>> AR_D1
   "metadata": {},
   "outputs": [],
   "source": [
    "#Field 0: 'datatime'\n",
    "#Field 1: 'temperature'\n",
    "#Field 2: 'windspeed'\n",
    "#Field 3: 'surface solar radiation' -Alvaro\n",
    "#Field 4: 'relative humidity' -Abdullah\n",
    "#Field 5: 'surface pressure' -Frazier\n",
    "#Field 6: 'total precipitation' -Simon\n",
    "#Field 7: 'city'\n",
    "#Field 8: 'event_id'\n",
    "#Field 9: 'latitude'\n",
    "#Field 10: 'longitude'\n",
    "#Field 11: 'outcome'\n",
    "\n",
<<<<<<< HEAD
    "\n",
    "data = pd.read_csv (FILE_NAME)\n",
    "data_nohead = pd.read_csv (FILE_NAME,header=None)\n",
    "\n",
    "#Take data to numPy\n",
    "numData = data_nohead.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = df.groupby('event_id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = averages[['temperature','wind_speed','surface_solar_radiation','relative_humidity', 'total_precipitation']]\n",
    "y = averages['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
=======
    "data = pd.read_csv (FILE_NAME)\n",
    "df = data.drop(columns=['Unnamed: 0'])\n",
    "event_ids = set(df['event_id'].to_numpy())"
   ]
  },
  {
   "source": [
    "## Create TimeSerie Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine slope of each weather attribute over time for each Tornado/Event\n",
    "temp_change = []\n",
    "wind_change = []\n",
    "rain_change = []\n",
    "radiation_change = []\n",
    "pressure_change = []\n",
    "humidity_change = []\n",
    "x = list(range(NUMBER_DAYS))\n",
    "\n",
    "for i in event_ids:\n",
    "    event = df.loc[df['event_id'] == i]\n",
    "    temp = event['temperature']\n",
    "    wind = event['wind_speed']\n",
    "    radiation = event['surface_solar_radiation']\n",
    "    humidity = event['relative_humidity']\n",
    "    pressure = event['surface_pressure']\n",
    "    rain = event['total_precipitation']\n",
    "\n",
    "    t_slope, intercept, r_value, p_value, std_err = stats.linregress(x, temp.tail(NUMBER_DAYS))\n",
    "    w_slope, intercept, r_value, p_value, std_err = stats.linregress(x, wind.tail(NUMBER_DAYS))\n",
    "    r_slope, intercept, r_value, p_value, std_err = stats.linregress(x, rain.tail(NUMBER_DAYS))\n",
    "    rd_slope, intercept, r_value, p_value, std_err = stats.linregress(x, radiation.tail(NUMBER_DAYS))\n",
    "    p_slope, intercept, r_value, p_value, std_err = stats.linregress(x, pressure.tail(NUMBER_DAYS))\n",
    "    h_slope, intercept, r_value, p_value, std_err = stats.linregress(x, humidity.tail(NUMBER_DAYS))\n",
    "\n",
    "    temp_change.append(t_slope)\n",
    "    wind_change.append(w_slope)\n",
    "    rain_change.append(r_slope)\n",
    "    radiation_change.append(rd_slope)\n",
    "    pressure_change.append(p_slope)\n",
    "    humidity_change.append(h_slope)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Dataframe with mean values of each Tornado/Event "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = df.groupby('event_id').tail(NUMBER_DAYS+7)\n",
    "averages = averages.groupby('event_id').mean()"
   ]
  },
  {
   "source": [
    "## Add Slope Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages['t_slope'] = temp_change\n",
    "averages['w_slope'] = wind_change\n",
    "averages['r_slope'] = rain_change\n",
    "averages['rd_slope'] = radiation_change\n",
    "averages['p_slope'] = pressure_change\n",
    "averages['h_slope'] = humidity_change"
   ]
  },
  {
   "source": [
    "## Model Prep"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = averages[['temperature','wind_speed','surface_solar_radiation','relative_humidity', 'total_precipitation', 't_slope', 'w_slope', 'r_slope', 'rd_slope', 'p_slope', 'h_slope']]\n",
    "y = averages['outcome']\n",
>>>>>>> AR_D1
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)"
=======
   "source": [
    "## Train Model with Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy:  0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "predictions = logisticRegr.predict(x_test)\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(\"Model Accuracy: \",score)"
>>>>>>> AR_D1
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
=======
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "regression coefficients: \n [[ 0.07573569  0.61778142  0.00266155 -0.00757722  2.53907333  1.18770639\n   1.53761794  1.28692345 -0.06994059 -0.0085332   0.1390187 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"regression coefficients: \\n\", logisticRegr.coef_)"
   ]
  },
  {
   "source": [
    "## Determine Individual Feature Strength"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
>>>>>>> AR_D1
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
<<<<<<< HEAD
      "0.7777777777777778\n"
=======
      "[0.71, 0.49, 0.69, 0.62, 0.84, 0.87, 0.78, 0.87, 0.69, 0.82, 0.49]\n"
>>>>>>> AR_D1
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
=======
    "# Returns array with model accuracy based on individial feature\n",
    "scores = []\n",
    "for i in range(11):\n",
    "\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(x_train.to_numpy()[:,i].reshape(-1,1), y_train)\n",
    "    score = logisticRegr.score(x_test.to_numpy()[:,i].reshape(-1,1), y_test)\n",
    "    scores.append(round(score,2))\n",
    "print(scores)"
>>>>>>> AR_D1
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_last_3_cols(text):\n",
    "    # reverse\n",
    "    text = text[::-1]\n",
    "    text = text.split(',', 2)\n",
    "    text.reverse()\n",
    "    text = [x[::-1] for x in text]\n",
    "    text[-1] = text[-1].replace('\\n', '')\n",
    "    return text # is a list\n",
    "\n",
    "def parse_before_notes(text):\n",
    "    state = 'MA'\n",
    "    start = text.find(',MA,')\n",
    "    if start < 0:\n",
    "        start = text.find('{')\n",
    "        data_1 = text[:start-1].split(',', 12)[:-1]\n",
    "        data_2 = text[start:].split(',', 13)\n",
    "        data = data_1 + data_2[:-1]\n",
    "        return data, data_2[-1]\n",
    "    \n",
    "    left = text[:start][::-1].split(',', 1)\n",
    "    city = left[0][::-1]\n",
    "    address = left[-1][::-1].split(',', 2)\n",
    "    if len(address) < 3:\n",
    "        address += [''] * (3 - len(address))\n",
    "    \n",
    "    end = start + 4\n",
    "    right = text[end:]\n",
    "    right = right.split(',', 1)\n",
    "    \n",
    "    if len(right[0]) < 4 or not right[0].isdigit():\n",
    "        zip = ''\n",
    "    else:\n",
    "#         if len(zip) == 4:\n",
    "#             zip\n",
    "        zip = right[0]\n",
    "    \n",
    "    \n",
    "    data = address + [city, state, zip]\n",
    "    \n",
    "    right = right[-1].split(',', 24)\n",
    "    \n",
    "    data += right[:-1]\n",
    "    \n",
    "    return data, right[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-opportunity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_excel('./data/CPCS TRIS Source Data/Priority2-RunsheetData-Full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/CPCS TRIS Source Data/Priority2-RunsheetData-Full.csv', mode='r', encoding='cp1252') as f:\n",
    "    lines = f.readlines()\n",
    "len(lines)    \n",
    "\n",
    "# f = open('./data/CPCS TRIS Source Data/Priority2-RunsheetData-Full.csv', mode='r', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-saudi",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lines[0].split(',')\n",
    "headers = ['LOG_ID',\n",
    " 'CASE_ID',\n",
    " 'CASE_NAME',\n",
    " 'CASE_OPENED',\n",
    " 'CLIENT_ID',\n",
    " 'CLIENT NAME',\n",
    " 'address_line1',\n",
    " 'address_line2',\n",
    " 'address_line3',\n",
    " 'city',\n",
    " 'state',\n",
    " 'zip',\n",
    " 'RACEID',\n",
    " 'RACE',\n",
    " 'ETHNICITYID',\n",
    " 'ETHNICITY',\n",
    " 'GENDER',\n",
    " 'DOB',\n",
    " 'ATTORNEYASSIGNED_1',\n",
    " 'ATTORNEYASSIGNED_2',\n",
    "\n",
    " 'COURTID',\n",
    " 'COURT',\n",
    " 'ABBR',\n",
    " 'RECORDEDBY GUID',\n",
    " 'RECORDEDBY',\n",
    "\n",
    " 'ASSIGNEDTO_1',\n",
    " 'ASSIGNEDTO_2',\n",
    " 'ASSIGNEDTO_3',\n",
    "\n",
    " 'DATE_RECORDED',\n",
    " 'ACTIVITY_DATE',\n",
    " 'ACTIVITY_TYPE',\n",
    " 'ACTIONTYPE',\n",
    " 'ACTIVITY_SUBTYPE',\n",
    " 'ACTIONSUBTYPE',\n",
    " 'OUTCOME',\n",
    " 'OUTCOME NAME',\n",
    " 'NOTES',\n",
    " 'OFFICE_ID',\n",
    " 'OFFICE NAME']\n",
    "# 70699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-teddy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns=lines[0].split(','))\n",
    "# headers = lines[0].split(',')\n",
    "pattern = re.compile('[\\d]{4,}-[\\d]{2,}-[\\d]{2,} [\\d]{2,}:[\\d]{2,}:[\\d]{2,}')\n",
    "err = []\n",
    "data = []\n",
    "\n",
    "i = 1\n",
    "maxline = 1032247 # len(lines)=1032247\n",
    "\n",
    "start = time.time()\n",
    "while i < maxline - 1:\n",
    "    dict_data = {}\n",
    "    row_end = False\n",
    "    line = lines[i]\n",
    "    # cut before address\n",
    "\n",
    "    line = line.split(',', 6)\n",
    "    match = None\n",
    "    for t in range(3, 6+1):\n",
    "        match = re.search(pattern, line[t][:19])\n",
    "        if match: break\n",
    "            \n",
    "    if match:\n",
    "        row = line[:2] + [','.join(line[2:t])] + line[t:-1]\n",
    "        line = ','.join(line).split(',', 6 + t - 3)\n",
    "#         print(row)\n",
    "    else:\n",
    "        row = line[:-1]\n",
    "        \n",
    "    before_notes, last = parse_before_notes(line[-1])\n",
    "    row += before_notes\n",
    "    \n",
    "    # next, parse notes\n",
    "    # log id has at least 4 digits\n",
    "    notes = last\n",
    "    j = i + 1\n",
    "    while j < maxline and not row_end:\n",
    "        next_line = lines[j]\n",
    "        tmp = next_line.split(',', 33)\n",
    "        if len(tmp) == 34 \\\n",
    "                and len(next_line) >= 4 \\\n",
    "                and len(tmp[0]) >= 4 \\\n",
    "                and tmp[0].isdigit() \\\n",
    "                and tmp[1].isdigit():\n",
    "            row_end = True\n",
    "            i = j\n",
    "            break\n",
    "        \n",
    "        # notes not end yet\n",
    "        else:\n",
    "            notes += next_line\n",
    "            j += 1\n",
    "\n",
    "    notes_with_3_col = split_last_3_cols(notes)\n",
    "    row += notes_with_3_col\n",
    "    \n",
    "    if '.' not in row[6]:\n",
    "        err.append(row)\n",
    "        continue\n",
    "    try:\n",
    "        dict_data = {headers[k]: row[k].strip() for k in range(len(headers))}\n",
    "    except Exception as e:\n",
    "        err.append(row)\n",
    "#         print(e)\n",
    "#         break\n",
    "    else:\n",
    "        data.append(dict_data)\n",
    "        if i % 10000 == 0:\n",
    "            print(i, end='\\t')\n",
    "\n",
    "print(f'cost time: {time.time() - start}\\n')\n",
    "\n",
    "d= {}\n",
    "for i, entry in enumerate(data):\n",
    "    # add a dictionary entry to the final dictionary\n",
    "    d[i] = entry\n",
    "\n",
    "print(f'err nums: {len(err)}\\n')\n",
    "df = pd.DataFrame.from_dict(d, orient='index', columns=headers)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df.to_excel('./data/CPCS TRIS Source Data/Priority2-RunsheetData-delete14187rows-clean.xlsx', encoding='utf8', index=None)\n",
    "print(f'cost time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-niagara",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(0 < df['CASE_OPENED'].str.len()) & (df['CASE_OPENED'].str.len() < 19)]\n",
    "\n",
    "# fix err, no need\n",
    "# for x in err:\n",
    "#     for i in range(5):\n",
    "#         del x[18]\n",
    "#         x.insert(18, '')\n",
    "# df.loc[0, 'address_line1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-knowing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tmp = pd.DataFrame(err, columns=headers)\n",
    "# tmp = df.append(tmp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(err)):\n",
    "    if err[i][0] == '70699':\n",
    "        print(i, len(err[i]), err[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-limitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, len(row), len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(s):\n",
    "    s = s.split(',')\n",
    "    return s\n",
    "\n",
    "s = '1,2,3,4,5'\n",
    "s.split(',', 0)\n",
    "# a(s), s\n",
    "# len(row), type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,22,3,4,5]\n",
    "a[4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('2009-11-12 00:00:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[\\d]{4,}-[\\d]{2,}-[\\d]{2,} [\\d]{2,}:[\\d]{2,}:[\\d]{2,}')\n",
    "index = re.search(pattern, '2009-11-12 00:00:00')\n",
    "if index:\n",
    "    print(index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

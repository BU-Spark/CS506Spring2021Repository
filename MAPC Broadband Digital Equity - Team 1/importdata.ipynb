{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPC Team 1 Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block for imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for reading data as a df and inserting into sql db\n",
    "def readData(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "def insertDataToDB(tablename, df,conn):\n",
    "    df.to_sql(tablename,conn, if_exists=\"replace\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to database cs506MAPC.db\n",
    "conn = sqlite3.connect('cs506MAPC.db')\n",
    "\n",
    "# read data from FCC June 2019 data. \n",
    "# If this line causes errors for you, you first need to download the data and \n",
    "# and unzip it into your local copy of your repository. (Can't upload the CSV to git because it's too large)\n",
    "# to download the zip file, go here --> https://github.com/MAPC/broadband-data-bu/tree/main/FCC%20data\n",
    "# NOTE: Make sure that you have the .csv file in the 'MAPC Broadband Equity - Team 1' folder and that you rename it\n",
    "# to \"fcc_data_june2019.csv\" \n",
    "\n",
    "df = readData(\"fcc_data_june2019.csv\")\n",
    "insertDataToDB(\"fcc_data_t\",df,conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Command to import cities with their long and lat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readData(\"MACityLongLat.csv\")\n",
    "insertDataToDB(\"CityLongLat_t\",df,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: censusblocks_t.blockcode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f45e504fe68d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"INSERT INTO censusblocks_t VALUES(?,?)\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcityName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcensusblock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: UNIQUE constraint failed: censusblocks_t.blockcode"
     ]
    }
   ],
   "source": [
    "qryStr = \"CREATE TABLE IF NOT EXISTS censusblocks_t (town TEXT, blockcode TEXT PRIMARY KEY NOT NULL)\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(qryStr)\n",
    "\n",
    "dict = {}\n",
    "\n",
    "\n",
    "for filename in os.listdir('census_blocks'):\n",
    "    readFile = os.path.join('census_blocks', filename)\n",
    "    names = filename.split(\".\")\n",
    "    cityName = names[0].upper()\n",
    "    f = open(readFile,\"r\", encoding=\"latin-1\");\n",
    "    lines = f.readlines();\n",
    "    count = 0\n",
    "    for line in lines:\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "            continue\n",
    "        entries = line.split(\";\")\n",
    "        if len(entries) != 6:\n",
    "            continue\n",
    "        tracts = entries[3].split(\".\");\n",
    "        censusblock = entries[1] + entries[2] + tracts[0] + tracts[1]\n",
    "        \n",
    "        if censusblock not in dict:\n",
    "            dict[censusblock] = cityName\n",
    "        else:\n",
    "            continue\n",
    "        cursor.execute(\"INSERT INTO censusblocks_t VALUES(?,?)\",(cityName,censusblock));\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readData(\"median_income.csv\")\n",
    "print(df.head(10))\n",
    "df_filtered = df[['ct10_id','mhi','mhi_me','o_mhi','o_mhi_me','r_mhi','r_mhi_me']]\n",
    "insertDataToDB(\"median_income_t\",df_filtered,conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readData(\"race_ethnicity.csv\")\n",
    "df = df.fillna(0)\n",
    "df_filtered = df[['ct10_id','nh_p','nhwhi_p','nhaa_p','nhna_p','nhas_p','nhpi_p','nhoth_p','nhmlt_p','lat_p']]\n",
    "insertDataToDB(\"race_ethnicity_t\",df_filtered,conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readData(\"demographic.csv\")\n",
    "df = df.fillna(0)\n",
    "df_filtered = df[['bg10_id','pop','male','female','fam','hh']]\n",
    "insertDataToDB(\"demographics_t\",df_filtered,conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readData(\"laborForceData.csv\")\n",
    "df = df.fillna(0)\n",
    "df_filtered = df[['bg10_id','emp','unemp','emp_p','unemp_p','lf']]\n",
    "insertDataToDB(\"laborforce_t\",df_filtered,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

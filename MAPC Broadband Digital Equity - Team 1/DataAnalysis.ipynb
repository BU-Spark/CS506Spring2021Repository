{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code block for imports \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('cs506MAPC.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display first 10 Providers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrystr =\"SELECT DISTINCT t1.ProviderName,substr(t1.BlockCode,0,12) as tractNum,t1.MaxAdDown,t1.MaxAdUp, t2.town, t3.Longitude, t3.Latitude FROM FCC_DATA_T t1, censusblocks_t t2, CityLongLat_t t3 WHERE substr(t1.BlockCode,0,12) = t2.blockcode AND t2.town = t3.town ORDER BY t2.town ASC\"\n",
    "\n",
    "\n",
    "#convert query results into dataframe\n",
    "df_filtered_providers = pd.read_sql_query(qrystr, conn)\n",
    "print(df_filtered_providers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Zero Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr2 = \"SELECT DISTINCT t1.ProviderName,substr(t1.BlockCode,0,12) as tractNum,t1.MaxAdDown,t1.MaxAdUp, t2.town, t3.Longitude, t3.Latitude FROM FCC_DATA_T t1, censusblocks_t t2, CityLongLat_t t3 WHERE MaxAdDown != 0.0 AND MaxAdUp != 0.0 and substr(t1.BlockCode,0,12) = t2.blockcode AND t2.town = t3.town ORDER BY t2.town ASC\"\n",
    "df_filtered_non_zero_providers = pd.read_sql_query(qryStr2, conn)\n",
    "print(df_filtered_non_zero_providers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr3 = \"SELECT DISTINCT t1.ProviderName,substr(t1.BlockCode,0,12) as tractNum,t1.MaxAdDown,t1.MaxAdUp, t2.town, t3.Longitude, t3.Latitude FROM FCC_DATA_T t1, censusblocks_t t2, CityLongLat_t t3 WHERE MaxAdDown = 0 AND MaxAdUp = 0 and substr(t1.BlockCode,0,12) = t2.blockcode AND t2.town = t3.town ORDER BY t2.town ASC\"\n",
    "df_filtered_zero_providers = pd.read_sql_query(qryStr3, conn)\n",
    "print(df_filtered_zero_providers.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Providers Per Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "town_dict = {}\n",
    "towns = df_filtered_zero_providers['town']\n",
    "providers = df_filtered_zero_providers['ProviderName']\n",
    "df_towns_providers = pd.concat([towns, providers], axis=1)\n",
    "numpy_arr = df_towns_providers.to_numpy()\n",
    "for i in range(len(numpy_arr)):\n",
    "    town_name = numpy_arr[i][0]\n",
    "    if town_name not in town_dict.keys():\n",
    "        town_dict[town_name] = [numpy_arr[i][1]]\n",
    "    elif numpy_arr[i][1] not in town_dict.get(town_name):\n",
    "        town_dict[town_name].append(numpy_arr[i][1])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "num_providers_dict = {}\n",
    "for key in town_dict.keys():\n",
    "    num_providers_dict[key] = len(town_dict.get(key))\n",
    "\n",
    "df_num_providers = pd.DataFrame(num_providers_dict.items(), columns=['Town', 'ProviderCount'])\n",
    "print(df_num_providers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display top/bottom 5 areas by number of providers (& Revere, Everett, Quincy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_most_providers = dict(sorted(num_providers_dict.items(), key=lambda item: item[1], reverse=True)[:5])\n",
    "five_least_providers = dict(sorted(num_providers_dict.items(), key=lambda item: item[1])[:5])\n",
    "everett_providers = {'EVERETT': num_providers_dict.get('EVERETT')}\n",
    "quincy_providers = {'QUINCY': num_providers_dict.get('QUINCY')}\n",
    "revere_providers = {'REVERE': num_providers_dict.get('REVERE')}\n",
    "plot_providers = {**five_most_providers, **five_least_providers, **everett_providers, **quincy_providers, **revere_providers}\n",
    "df_plot_providers = pd.DataFrame(plot_providers.items(), columns=['Town', 'ProviderCount'])\n",
    "\n",
    "y_max_tick = max(plot_providers.values())\n",
    "\n",
    "print(df_plot_providers)\n",
    "df_plot_providers.plot(x='Town', y='ProviderCount', kind='bar')\n",
    "plt.yticks(np.arange(0, y_max_tick, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAdDown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr4 = \"SELECT DISTINCT t1.MaxAdDown, t2.town as Town FROM FCC_DATA_T t1, censusblocks_t t2, CityLongLat_t t3 WHERE MaxAdDown != 0.0 AND MaxAdUp != 0.0 and substr(t1.BlockCode,0,12) = t2.blockcode AND t2.town = t3.town GROUP BY t2.town ORDER BY MaxAdDown DESC\"\n",
    "df_filtered_max_down = pd.read_sql_query(qryStr4, conn)\n",
    "print(df_filtered_max_down.head(10))\n",
    "\n",
    "top_ten = df_filtered_max_down.nlargest(10, ['MaxAdDown'])\n",
    "bottom_ten = df_filtered_max_down.nsmallest(10, ['MaxAdDown'])\n",
    "revere = df_filtered_max_down.loc[df_filtered_max_down['Town'] == 'REVERE']\n",
    "quincy = df_filtered_max_down.loc[df_filtered_max_down['Town'] == 'QUINCY']\n",
    "everett = df_filtered_max_down.loc[df_filtered_max_down['Town'] == 'EVERETT']\n",
    "\n",
    "combined_max_down_top = pd.concat([top_ten, revere, quincy, everett], axis=0)\n",
    "combined_max_down_top = combined_max_down_top.reset_index(drop=True)\n",
    "combined_max_down_bottom = pd.concat([bottom_ten, revere, quincy, everett], axis=0)\n",
    "combined_max_down_bottom = combined_max_down_bottom.reset_index(drop=True)\n",
    "\n",
    "combined_max_down_top.plot(x='Town', y='MaxAdDown', kind='bar', title = \"Top 10 Town Download Speeds\")\n",
    "plt.show()\n",
    "\n",
    "combined_max_down_bottom.plot(x='Town', y='MaxAdDown', kind='bar', title = \"Bottom 10 Town Download Speeds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaxAdUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr5 = \"SELECT DISTINCT t1.MaxAdUp, t2.town as Town FROM FCC_DATA_T t1, censusblocks_t t2, CityLongLat_t t3 WHERE MaxAdDown != 0.0 AND MaxAdUp != 0.0 and substr(t1.BlockCode,0,12) = t2.blockcode AND t2.town = t3.town GROUP BY t2.town ORDER BY MaxAdUp DESC\"\n",
    "df_filtered_max_up = pd.read_sql_query(qryStr5, conn)\n",
    "print(df_filtered_max_up.head(10))\n",
    "\n",
    "top_ten = df_filtered_max_up.nlargest(10, ['MaxAdUp'])\n",
    "bottom_ten = df_filtered_max_up.nsmallest(10, ['MaxAdUp'])\n",
    "revere = df_filtered_max_up.loc[df_filtered_max_up['Town'] == 'REVERE']\n",
    "quincy = df_filtered_max_up.loc[df_filtered_max_up['Town'] == 'QUINCY']\n",
    "everett = df_filtered_max_up.loc[df_filtered_max_up['Town'] == 'EVERETT']\n",
    "\n",
    "combined_max_up_top = pd.concat([top_ten, revere, quincy, everett], axis=0)\n",
    "combined_max_up_top = combined_max_up_top.reset_index(drop=True)\n",
    "combined_max_up_bottom = pd.concat([bottom_ten, revere, quincy, everett], axis=0)\n",
    "combined_max_up_bottom = combined_max_up_bottom.reset_index(drop=True)\n",
    "\n",
    "combined_max_up_top.plot(x='Town', y='MaxAdUp', kind='bar', title = \"Top 10 Town Upload Speeds\")\n",
    "plt.show()\n",
    "\n",
    "combined_max_up_bottom.plot(x='Town', y='MaxAdUp', kind='bar', title = \"Bottom 10 Town Upload Speeds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Income  (Census Tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr6 = \"SELECT t2.Town as Town, AVG(t1.mhi) as 'Average Median Income' FROM median_income_t t1, censusblocks_t t2 WHERE t2.blockcode = t1.ct10_id and t1.mhi > 1 GROUP BY t2.Town;\"\n",
    "town_median_income  = pd.read_sql_query(qryStr6, conn)\n",
    "town_median_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "town_median_income.sort_values(by=['Average Median Income'])\n",
    "top_five_towns = town_median_income.nlargest(5, ['Average Median Income'])\n",
    "bottom_five_towns = town_median_income.nsmallest(5, ['Average Median Income'])\n",
    "revere = town_median_income.loc[town_median_income['Town'] == 'REVERE']\n",
    "quincy = town_median_income.loc[town_median_income['Town'] == 'QUINCY']\n",
    "everett = town_median_income.loc[town_median_income['Town'] == 'EVERETT']\n",
    "combined_median_income_df = pd.concat([top_five_towns, bottom_five_towns, revere, quincy, everett], axis=0)\n",
    "combined_median_income_df = combined_median_income_df.reset_index(drop=True)\n",
    "combined_median_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_median_income_df.plot(x='Town', y='Average Median Income', kind='bar') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr7 = \"SELECT t2.Town as Town, ROUND(AVG(t1.MaxAdDown),2) as AverageMaxDown, ROUND(AVG(t1.MaxAdUp),2) as AverageMaxUp FROM fcc_data_t t1, censusblocks_t t2 WHERE  substr(t1.BlockCode,0,12) = t2.blockcode AND (t1.MaxAdDown > 0 AND t1.MaxAdUp > 0) GROUP BY t2.TOWN\"\n",
    "town_average_speeds  = pd.read_sql_query(qryStr7, conn)\n",
    "town_average_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dover = town_average_speeds.loc[town_average_speeds['Town'] == 'DOVER']\n",
    "wellesley = town_average_speeds.loc[town_average_speeds['Town'] == 'WELLESLEY']\n",
    "boxford = town_average_speeds.loc[town_average_speeds['Town'] == 'BOXFORD']\n",
    "lexington = town_average_speeds.loc[town_average_speeds['Town'] == 'LEXINGTON']\n",
    "hopkinton = town_average_speeds.loc[town_average_speeds['Town'] == 'HOPKINTON']\n",
    "springfield = town_average_speeds.loc[town_average_speeds['Town'] == 'SPRINGFIELD']\n",
    "north_adams = town_average_speeds.loc[town_average_speeds['Town'] == 'NORTH ADAMS']\n",
    "lawrence = town_average_speeds.loc[town_average_speeds['Town'] == 'LAWRENCE']\n",
    "holyoke = town_average_speeds.loc[town_average_speeds['Town'] == 'HOLYOKE']\n",
    "fall_river = town_average_speeds.loc[town_average_speeds['Town'] == 'FALL RIVER']\n",
    "revere = town_average_speeds.loc[town_average_speeds['Town'] == 'REVERE']\n",
    "quincy = town_average_speeds.loc[town_average_speeds['Town'] == 'QUINCY']\n",
    "everett = town_average_speeds.loc[town_average_speeds['Town'] == 'EVERETT']\n",
    "\n",
    "combined_average_speed_df = pd.concat([dover, wellesley, boxford, lexington, hopkinton, springfield, north_adams, lawrence, holyoke, fall_river, revere, quincy, everett], axis=0)\n",
    "combined_average_speed_df = combined_average_speed_df.reset_index(drop=True)\n",
    "combined_average_speed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_average_speed_df.plot(x='Town', y='AverageMaxDown', kind='bar') \n",
    "plt.show()\n",
    "\n",
    "# add Average Max Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_average_speed_df.plot(x='Town', y='AverageMaxUp', kind='bar') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income_and_speed_df = combined_average_speed_df\n",
    "median_income_and_speed_df['Average Median Income'] = combined_median_income_df['Average Median Income']\n",
    "median_income_and_speed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = median_income_and_speed_df.plot(kind='scatter', x='Average Median Income', y='AverageMaxDown', title='Median income vs Average Max Down Speed',)    \n",
    "\n",
    "# annotate points in axis\n",
    "for idx, row in median_income_and_speed_df.iterrows():\n",
    "    ax1.annotate(row['Town'], (row['Average Median Income'], row['AverageMaxDown']))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = median_income_and_speed_df[:6].plot(kind='scatter', x='Average Median Income', y='AverageMaxUp', title='Median income vs Average Max Up Speed',)    \n",
    "\n",
    "# annotate points in axis\n",
    "for idx, row in median_income_and_speed_df[:6].iterrows():\n",
    "    ax2.annotate(row['Town'], (row['Average Median Income'], row['AverageMaxUp']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax3 = median_income_and_speed_df[7:].plot(kind='scatter', x='Average Median Income', y='AverageMaxUp', title='Median income vs Average Max Up Speed',)    \n",
    "\n",
    "# annotate points in axis\n",
    "for idx, row in median_income_and_speed_df[7:].iterrows():\n",
    "    ax3.annotate(row['Town'], (row['Average Median Income'], row['AverageMaxUp']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "qryStr6 =\"SELECT t2.Town as Town, ROUND(AVG(t1.MaxAdDown),2) as AverageMaxDown, ROUND(AVG(t1.MaxAdUp),2) as AverageMaxUp,ROUND(AVG(t3.nh_p),2) as nh_p, ROUND(AVG(t3.nhwhi_p),2) as nhwhi_p,ROUND(AVG(t3.nhaa_p),2) as nhaa_p, ROUND(AVG(t3.nhna_p),2) as nhna_p,ROUND(AVG(t3.nhas_p),2) as nhas_p, ROUND(AVG(t3.nhpi_p),2) as nhpi_p,ROUND(AVG(t3.nhoth_p),2) as nhoth_p, ROUND(AVG(t3.nhmlt_p),2) as nhmlt_p,ROUND(AVG(t3.lat_p),2) as lat_p FROM fcc_data_t t1, censusblocks_t t2, race_ethnicity_t t3 WHERE substr(t1.BlockCode,0,12) = t2.blockcode  AND (t1.MaxAdDown > 0 AND t1.MaxAdUp > 0) AND t2.blockcode = t3.ct10_id GROUP BY t2.TOWN\"\n",
    "df_averages_percentage = pd.read_sql_query(qryStr6, conn)\n",
    "print(df_averages_percentage.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_averages_percentage = df_averages_percentage.rename(columns={\"nh_p\":\"Non-Hispanic\",\"nhwhi_p\": \"Non-Hispanic White\",\n",
    "                                      \"nhaa_p\":\"Non-Hispanic Black or African American\",\"nhna_p\": \"Non-Hispanic American Indian and Alaska Native\",\n",
    "                                      \"nhas_p\":\"Non-Hispanic Asian\",\"nhpi_p\": \"Non-Hispanic Native Hawaiian/Other Pacific Islander\",\n",
    "                                      \"nhoth_p\":\"Non-Hispanic Some Other Races\",\"nhmlt_p\": \"Non-Hispanic Two or More Races\",\n",
    "                                      \"lat_p\":\"Hispanic/Latino\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_averages_percentage.to_csv('MaxSpeed_Race.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_averages_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-concentration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_averages_percentage[['Non-Hispanic Asian','AverageMaxDown']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Hispanic/Latino'], df_averages_percentage['AverageMaxDown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Hispanic/Latino'], df_averages_percentage['AverageMaxUp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic Black or African American'], df_averages_percentage['AverageMaxUp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic Black or African American'], df_averages_percentage['AverageMaxDown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic White'], df_averages_percentage['AverageMaxDown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic White'], df_averages_percentage['AverageMaxUp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic Asian'], df_averages_percentage['AverageMaxUp'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-background",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim(0,100)\n",
    "plt.scatter(df_averages_percentage['Non-Hispanic Asian'], df_averages_percentage['AverageMaxDown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = df_num_providers['Town'].to_list()\n",
    "l2 = df_averages_percentage['Town'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diff(li1, li2):\n",
    "    return (list(list(set(li1)-set(li2)) + list(set(li2)-set(li1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
